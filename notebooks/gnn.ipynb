{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running locally\n"
          ]
        }
      ],
      "source": [
        "# Check if running on Colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running on Google Colab\")\n",
        "    !pip install torch-geometric\n",
        "    !pip install python-dateutil\n",
        "else:\n",
        "    print(\"Running locally\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU available, using CPU\n",
            "\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    \n",
        "    # Check for B200/Blackwell or other high-end GPUs\n",
        "    gpu_name = torch.cuda.get_device_name(0).lower()\n",
        "    if 'b200' in gpu_name or 'b100' in gpu_name or 'blackwell' in gpu_name:\n",
        "        print(\"Detected Blackwell GPU - using bfloat16 for optimal performance\")\n",
        "        USE_BF16 = True\n",
        "    elif 'h100' in gpu_name or 'a100' in gpu_name:\n",
        "        print(\"Detected Hopper/Ampere GPU - using bfloat16\")\n",
        "        USE_BF16 = True\n",
        "    else:\n",
        "        print(\"Using float16 for mixed precision\")\n",
        "        USE_BF16 = False\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    USE_BF16 = False\n",
        "    print(\"No GPU available, using CPU\")\n",
        "\n",
        "print(f\"\\nUsing device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive (Colab only)\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    GRAPH_DIR = '/content/drive/MyDrive/CS224W/graphs'\n",
        "else:\n",
        "    GRAPH_DIR = '../data/processed/graphs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 177 communities\n",
            "  - 3dprinting.stackexchange.com: 99 monthly graphs\n",
            "  - academia.stackexchange.com: 148 monthly graphs\n",
            "  - ai.stackexchange.com: 92 monthly graphs\n",
            "  - android.stackexchange.com: 175 monthly graphs\n",
            "  - anime.stackexchange.com: 136 monthly graphs\n",
            "  ... and 172 more\n"
          ]
        }
      ],
      "source": [
        "# Verify data directory exists\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "graph_dir = Path(GRAPH_DIR)\n",
        "\n",
        "if not graph_dir.exists():\n",
        "    print(f\"ERROR: Graph directory not found: {graph_dir}\")\n",
        "else:\n",
        "    communities = [d.name for d in graph_dir.iterdir() if d.is_dir()]\n",
        "    print(f\"Found {len(communities)} communities\")\n",
        "    # Show first few\n",
        "    for comm in sorted(communities)[:5]:\n",
        "        comm_path = graph_dir / comm\n",
        "        n_graphs = len(list(comm_path.glob('*.pt')))\n",
        "        print(f\"  - {comm}: {n_graphs} monthly graphs\")\n",
        "    if len(communities) > 5:\n",
        "        print(f\"  ... and {len(communities) - 5} more\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph = torch.load(\"2023-05.pt\", weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'qpd': 9.903225806451612,\n",
              " 'answer_rate': 0.1758957654723127,\n",
              " 'retention': 0.1589041095890411,\n",
              " 'growth': 0.2644628099173554}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Model and Dataset Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.nn import SAGEConv, HeteroConv\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TemporalCommunityGNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Temporal GNN for predicting community health trajectories.\n",
        "    Optimized for GPU execution - no torch.compile, uses AMP-friendly operations.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        user_feat_dim: int,\n",
        "        tag_feat_dim: int,\n",
        "        hidden_dim: int = 128,\n",
        "        num_conv_layers: int = 2,\n",
        "        num_transformer_layers: int = 2,\n",
        "        num_attention_heads: int = 4,\n",
        "        dropout: float = 0.1,\n",
        "        transformer_ffn_dim: int = 256\n",
        "    ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_conv_layers = num_conv_layers\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        # Feature projection (LayerNorm is AMP-friendly)\n",
        "        self.user_norm = nn.LayerNorm(user_feat_dim)\n",
        "        self.tag_norm = nn.LayerNorm(tag_feat_dim)\n",
        "        self.user_proj = nn.Linear(user_feat_dim, hidden_dim)\n",
        "        self.tag_proj = nn.Linear(tag_feat_dim, hidden_dim)\n",
        "        \n",
        "        # Graph conv layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_conv_layers):\n",
        "            conv = HeteroConv({\n",
        "                (\"tag\", \"cooccurs\", \"tag\"): SAGEConv(hidden_dim, hidden_dim, aggr=\"mean\"),\n",
        "                (\"user\", \"contributes\", \"tag\"): SAGEConv((hidden_dim, hidden_dim), hidden_dim, aggr=\"mean\"),\n",
        "                (\"tag\", \"contributed_to_by\", \"user\"): SAGEConv((hidden_dim, hidden_dim), hidden_dim, aggr=\"mean\"),\n",
        "            }, aggr=\"mean\")\n",
        "            self.convs.append(conv)\n",
        "        \n",
        "        self.conv_dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        # Temporal transformer\n",
        "        community_emb_dim = 2 * hidden_dim\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=community_emb_dim,\n",
        "            nhead=num_attention_heads,\n",
        "            dim_feedforward=transformer_ffn_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.temporal_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_transformer_layers)\n",
        "        \n",
        "        # Prediction heads\n",
        "        self.qpd_head = nn.Linear(community_emb_dim, 1)\n",
        "        self.ansrate_head = nn.Linear(community_emb_dim, 1)\n",
        "        self.retention_head = nn.Linear(community_emb_dim, 1)\n",
        "\n",
        "    def forward_single_graph(self, x_dict, edge_index_dict):\n",
        "        \"\"\"Process a single graph to get community embedding.\"\"\"\n",
        "        # Project features\n",
        "        projected = {}\n",
        "        if \"user\" in x_dict:\n",
        "            projected[\"user\"] = self.user_proj(self.user_norm(x_dict[\"user\"]))\n",
        "        if \"tag\" in x_dict:\n",
        "            projected[\"tag\"] = self.tag_proj(self.tag_norm(x_dict[\"tag\"]))\n",
        "        \n",
        "        # Apply conv layers\n",
        "        x = projected\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index_dict)\n",
        "            x = {k: torch.relu(v) for k, v in x.items()}\n",
        "            x = {k: self.conv_dropout(v) for k, v in x.items()}\n",
        "        \n",
        "        # Pool to community embedding\n",
        "        user_pooled = x[\"user\"].mean(dim=0)\n",
        "        tag_pooled = x[\"tag\"].mean(dim=0)\n",
        "        return torch.cat([user_pooled, tag_pooled])\n",
        "\n",
        "    def forward(self, batch_monthly_graphs):\n",
        "        \"\"\"Forward pass for batched temporal sequences.\"\"\"\n",
        "        batch_embeddings = []\n",
        "        \n",
        "        for community_graphs in batch_monthly_graphs:\n",
        "            monthly_embs = []\n",
        "            for graph in community_graphs:\n",
        "                if isinstance(graph, tuple):\n",
        "                    x_dict, edge_index_dict = graph\n",
        "                else:\n",
        "                    x_dict = graph.x_dict\n",
        "                    edge_index_dict = graph.edge_index_dict\n",
        "                emb = self.forward_single_graph(x_dict, edge_index_dict)\n",
        "                monthly_embs.append(emb)\n",
        "            batch_embeddings.append(torch.stack(monthly_embs))\n",
        "        \n",
        "        # [batch, 12, emb_dim]\n",
        "        batch_embeddings = torch.stack(batch_embeddings)\n",
        "        \n",
        "        # Temporal encoding\n",
        "        temporal_out = self.temporal_encoder(batch_embeddings)\n",
        "        final_repr = temporal_out[:, -1, :]\n",
        "        \n",
        "        return {\n",
        "            \"qpd\": self.qpd_head(final_repr).squeeze(-1),\n",
        "            \"answer_rate\": self.ansrate_head(final_repr).squeeze(-1),\n",
        "            \"retention\": self.retention_head(final_repr).squeeze(-1),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CachedTemporalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset with in-memory caching for fast GPU training.\n",
        "    Loads all data into memory once, then serves from cache.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        graph_dir: Path,\n",
        "        split: str = 'train',\n",
        "        sequence_length: int = 12,\n",
        "        prediction_horizon: int = 6,\n",
        "        max_samples: int = None,  # Limit samples for faster testing\n",
        "        cache_in_memory: bool = True\n",
        "    ):\n",
        "        self.graph_dir = Path(graph_dir)\n",
        "        self.split = split\n",
        "        self.sequence_length = sequence_length\n",
        "        self.prediction_horizon = prediction_horizon\n",
        "        self.cache_in_memory = cache_in_memory\n",
        "        self.cache = {}\n",
        "        \n",
        "        # Temporal splits\n",
        "        self.split_ranges = {\n",
        "            'train': ('2008-01', '2020-06'),\n",
        "            'val': ('2020-07', '2022-09'),\n",
        "            'test': ('2022-10', '2023-09')\n",
        "        }\n",
        "        \n",
        "        self.samples = self._build_sample_index()\n",
        "        if max_samples:\n",
        "            self.samples = self.samples[:max_samples]\n",
        "        \n",
        "        print(f\"{split.upper()} Dataset: {len(self.samples)} samples\")\n",
        "        \n",
        "        # Pre-cache if requested\n",
        "        if cache_in_memory and len(self.samples) > 0:\n",
        "            print(f\"Pre-caching {split} data...\")\n",
        "            self._precache_all()\n",
        "    \n",
        "    def _build_sample_index(self) -> List[Dict]:\n",
        "        samples = []\n",
        "        start_month, end_month = self.split_ranges[self.split]\n",
        "        min_graphs = self.sequence_length + self.prediction_horizon\n",
        "        \n",
        "        for community_dir in sorted(self.graph_dir.iterdir()):\n",
        "            if not community_dir.is_dir():\n",
        "                continue\n",
        "            \n",
        "            available_months = sorted([f.stem for f in community_dir.glob('*.pt')])\n",
        "            if len(available_months) < min_graphs:\n",
        "                continue\n",
        "            \n",
        "            for i, month_t in enumerate(available_months):\n",
        "                if not (start_month <= month_t <= end_month):\n",
        "                    continue\n",
        "                if i < self.sequence_length - 1:\n",
        "                    continue\n",
        "                \n",
        "                target_idx = i + self.prediction_horizon\n",
        "                if target_idx >= len(available_months):\n",
        "                    continue\n",
        "                \n",
        "                seq_start = i - self.sequence_length + 1\n",
        "                seq_months = available_months[seq_start:i+1]\n",
        "                target_month = available_months[target_idx]\n",
        "                \n",
        "                # Simple consecutive check\n",
        "                if self._is_consecutive(seq_months, target_month):\n",
        "                    samples.append({\n",
        "                        'community': community_dir.name,\n",
        "                        'sequence_months': seq_months,\n",
        "                        'target_month': target_month\n",
        "                    })\n",
        "        return samples\n",
        "    \n",
        "    def _is_consecutive(self, seq_months, target_month):\n",
        "        \"\"\"Check if months form consecutive sequence.\"\"\"\n",
        "        try:\n",
        "            dates = [datetime.strptime(m, '%Y-%m') for m in seq_months]\n",
        "            for i in range(1, len(dates)):\n",
        "                if dates[i] != dates[i-1] + relativedelta(months=1):\n",
        "                    return False\n",
        "            target_date = datetime.strptime(target_month, '%Y-%m')\n",
        "            expected = dates[-1] + relativedelta(months=self.prediction_horizon)\n",
        "            return target_date == expected\n",
        "        except:\n",
        "            return False\n",
        "    \n",
        "    def _precache_all(self):\n",
        "        \"\"\"Load all graphs into memory.\"\"\"\n",
        "        for idx in tqdm(range(len(self.samples)), desc='Caching'):\n",
        "            if idx not in self.cache:\n",
        "                self.cache[idx] = self._load_sample(idx)\n",
        "    \n",
        "    def _load_sample(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        community_dir = self.graph_dir / sample['community']\n",
        "        \n",
        "        graphs = []\n",
        "        for month in sample['sequence_months']:\n",
        "            graph = torch.load(community_dir / f\"{month}.pt\", weights_only=False)\n",
        "            graphs.append(graph)\n",
        "        \n",
        "        target_graph = torch.load(community_dir / f\"{sample['target_month']}.pt\", weights_only=False)\n",
        "        targets = target_graph.y\n",
        "        \n",
        "        return graphs, targets\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.cache_in_memory and idx in self.cache:\n",
        "            return self.cache[idx]\n",
        "        return self._load_sample(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for batching.\"\"\"\n",
        "    batch_graphs = []\n",
        "    batch_targets = {'qpd': [], 'answer_rate': [], 'retention': []}\n",
        "    \n",
        "    for graphs, targets in batch:\n",
        "        batch_graphs.append(graphs)\n",
        "        for key in batch_targets:\n",
        "            batch_targets[key].append(targets[key])\n",
        "    \n",
        "    for key in batch_targets:\n",
        "        batch_targets[key] = torch.tensor(batch_targets[key], dtype=torch.float32)\n",
        "    \n",
        "    return batch_graphs, batch_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN Dataset: 13359 samples\n",
            "Pre-caching train data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28c819ca94c64ed4be44689974a69962",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Caching:   0%|          | 0/13359 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAL Dataset: 4484 samples\n",
            "Pre-caching val data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "211fb74cd4d7425282417c023ec1644a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Caching:   0%|          | 0/4484 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Datasets created: 13359 train, 4484 val\n"
          ]
        }
      ],
      "source": [
        "# Create datasets - limit samples for fast proof of concept\n",
        "# Set max_samples=None to use all data once you confirm it works\n",
        "MAX_SAMPLES = None  # Limit for fast testing\n",
        "\n",
        "train_dataset = CachedTemporalDataset(\n",
        "    graph_dir=GRAPH_DIR,\n",
        "    split='train',\n",
        "    max_samples=MAX_SAMPLES,\n",
        "    cache_in_memory=True\n",
        ")\n",
        "\n",
        "val_dataset = CachedTemporalDataset(\n",
        "    graph_dir=GRAPH_DIR,\n",
        "    split='val',\n",
        "    max_samples=MAX_SAMPLES,\n",
        "    cache_in_memory=True\n",
        ")\n",
        "\n",
        "print(f\"\\nDatasets created: {len(train_dataset)} train, {len(val_dataset)} val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample has 12 monthly graphs\n",
            "Graph structure:\n",
            "  Users: torch.Size([75, 5])\n",
            "  Tags: torch.Size([109, 7])\n",
            "\n",
            "Targets: {'qpd': 1.5, 'answer_rate': 0.5777777777777777, 'retention': 0.29508196721311475, 'growth': 0.0}\n"
          ]
        }
      ],
      "source": [
        "# Inspect a sample\n",
        "if len(train_dataset) > 0:\n",
        "    sample_graphs, sample_targets = train_dataset[0]\n",
        "    print(f\"Sample has {len(sample_graphs)} monthly graphs\")\n",
        "    g = sample_graphs[0]\n",
        "    print(f\"Graph structure:\")\n",
        "    print(f\"  Users: {g['user'].x.shape}\")\n",
        "    print(f\"  Tags: {g['tag'].x.shape}\")\n",
        "    print(f\"\\nTargets: {sample_targets}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train batches: 7, Val batches: 3\n"
          ]
        }
      ],
      "source": [
        "# Create DataLoaders - use larger batch size for B200\n",
        "# B200 has 192GB memory, so we can use much larger batches\n",
        "BATCH_SIZE = 2048  # Increase for B200\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=0,\n",
        "    pin_memory=False  # Data already in memory\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=0,\n",
        "    pin_memory=False\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User features: 5, Tag features: 7\n"
          ]
        }
      ],
      "source": [
        "# Get feature dimensions from data\n",
        "if len(train_dataset) > 0:\n",
        "    sample_graphs, _ = train_dataset[0]\n",
        "    USER_FEAT_DIM = sample_graphs[0]['user'].x.shape[1]\n",
        "    TAG_FEAT_DIM = sample_graphs[0]['tag'].x.shape[1]\n",
        "else:\n",
        "    USER_FEAT_DIM = 5\n",
        "    TAG_FEAT_DIM = 7\n",
        "\n",
        "print(f\"User features: {USER_FEAT_DIM}, Tag features: {TAG_FEAT_DIM}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model parameters: 133,979\n"
          ]
        }
      ],
      "source": [
        "model = TemporalCommunityGNN(\n",
        "    user_feat_dim=USER_FEAT_DIM,\n",
        "    tag_feat_dim=TAG_FEAT_DIM,\n",
        "    hidden_dim=64,\n",
        "    num_conv_layers=2,\n",
        "    num_transformer_layers=1,\n",
        "    num_attention_heads=4,\n",
        "    dropout=0.2,\n",
        "    transformer_ffn_dim=64\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Model parameters: {n_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training with AMP (Automatic Mixed Precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def move_to_device(batch_graphs, device):\n",
        "    \"\"\"Move graphs to device efficiently.\"\"\"\n",
        "    return [[g.to(device, non_blocking=True) for g in graphs] for graphs in batch_graphs]\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion, device, scaler, use_amp):\n",
        "    \"\"\"Train for one epoch with AMP.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    n_batches = 0\n",
        "    \n",
        "    # Determine dtype for autocast\n",
        "    amp_dtype = torch.bfloat16 if USE_BF16 else torch.float16\n",
        "    \n",
        "    pbar = tqdm(loader, desc='Training')\n",
        "    for batch_graphs, batch_targets in pbar:\n",
        "        batch_graphs = move_to_device(batch_graphs, device)\n",
        "        batch_targets = {k: v.to(device, non_blocking=True) for k, v in batch_targets.items()}\n",
        "        \n",
        "        optimizer.zero_grad(set_to_none=True)  # Faster than zero_grad()\n",
        "        \n",
        "        # Forward with AMP\n",
        "        with torch.amp.autocast('cuda', enabled=use_amp, dtype=amp_dtype):\n",
        "            predictions = model(batch_graphs)\n",
        "            \n",
        "            loss = (\n",
        "                criterion(predictions['qpd'], batch_targets['qpd']) +\n",
        "                criterion(predictions['answer_rate'], batch_targets['answer_rate']) +\n",
        "                criterion(predictions['retention'], batch_targets['retention'])\n",
        "            ) / 3.0\n",
        "        \n",
        "        # Backward with scaler\n",
        "        if use_amp and not USE_BF16:  # scaler only needed for fp16\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        n_batches += 1\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "    \n",
        "    return total_loss / max(n_batches, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device, use_amp):\n",
        "    \"\"\"Evaluate model.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    n_batches = 0\n",
        "    \n",
        "    all_preds = {'qpd': [], 'answer_rate': [], 'retention': []}\n",
        "    all_targets = {'qpd': [], 'answer_rate': [], 'retention': []}\n",
        "    \n",
        "    amp_dtype = torch.bfloat16 if USE_BF16 else torch.float16\n",
        "    \n",
        "    for batch_graphs, batch_targets in tqdm(loader, desc='Evaluating', leave=False):\n",
        "        batch_graphs = move_to_device(batch_graphs, device)\n",
        "        batch_targets = {k: v.to(device, non_blocking=True) for k, v in batch_targets.items()}\n",
        "        \n",
        "        with torch.amp.autocast('cuda', enabled=use_amp, dtype=amp_dtype):\n",
        "            predictions = model(batch_graphs)\n",
        "            \n",
        "            loss = (\n",
        "                criterion(predictions['qpd'], batch_targets['qpd']) +\n",
        "                criterion(predictions['answer_rate'], batch_targets['answer_rate']) +\n",
        "                criterion(predictions['retention'], batch_targets['retention'])\n",
        "            ) / 3.0\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        n_batches += 1\n",
        "        \n",
        "        for key in all_preds:\n",
        "            all_preds[key].extend(predictions[key].float().cpu().numpy())\n",
        "            all_targets[key].extend(batch_targets[key].float().cpu().numpy())\n",
        "    \n",
        "    # Compute R² for each metric\n",
        "    r2_scores = {}\n",
        "    for key in all_preds:\n",
        "        preds = np.array(all_preds[key])\n",
        "        targets = np.array(all_targets[key])\n",
        "        ss_res = np.sum((targets - preds) ** 2)\n",
        "        ss_tot = np.sum((targets - targets.mean()) ** 2)\n",
        "        r2_scores[key] = 1 - ss_res / (ss_tot + 1e-8)\n",
        "    \n",
        "    return total_loss / max(n_batches, 1), r2_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training config:\n",
            "  Device: cuda\n",
            "  AMP: True\n",
            "  Dtype: bfloat16\n",
            "  Batch size: 2048\n",
            "  Epochs: 5\n"
          ]
        }
      ],
      "source": [
        "# Training setup\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 5\n",
        "USE_AMP = torch.cuda.is_available()  # Enable AMP on GPU\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP and not USE_BF16)\n",
        "\n",
        "print(f\"Training config:\")\n",
        "print(f\"  Device: {device}\")\n",
        "print(f\"  AMP: {USE_AMP}\")\n",
        "print(f\"  Dtype: {'bfloat16' if USE_BF16 else 'float16' if USE_AMP else 'float32'}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Epochs: {NUM_EPOCHS}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing single batch...\n",
            "✓ Single batch completed in 11.431s\n",
            "  Loss: 815.5268\n",
            "  GPU memory: 2.34 GB\n"
          ]
        }
      ],
      "source": [
        "# Quick test - single batch forward/backward\n",
        "print(\"Testing single batch...\")\n",
        "\n",
        "if len(train_loader) > 0:\n",
        "    batch_graphs, batch_targets = next(iter(train_loader))\n",
        "    batch_graphs = move_to_device(batch_graphs, device)\n",
        "    batch_targets = {k: v.to(device) for k, v in batch_targets.items()}\n",
        "    \n",
        "    amp_dtype = torch.bfloat16 if USE_BF16 else torch.float16\n",
        "    \n",
        "    # Time forward pass\n",
        "    import time\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    start = time.time()\n",
        "    \n",
        "    with torch.amp.autocast('cuda', enabled=USE_AMP, dtype=amp_dtype):\n",
        "        preds = model(batch_graphs)\n",
        "        loss = criterion(preds['qpd'], batch_targets['qpd'])\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    elapsed = time.time() - start\n",
        "    \n",
        "    print(f\"✓ Single batch completed in {elapsed:.3f}s\")\n",
        "    print(f\"  Loss: {loss.item():.4f}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"  GPU memory: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"No data in train_loader\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Starting training...\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8aa7a1d2a6e4486c91301c9cced21dff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3914024fcaa94c4db61fb035ed43e45e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  1/5 | Train: 593.7313 | Val: 181.3873 | R²: qpd=-0.087, ans=-1.158, ret=-74.413 ★\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ace7dbc850614b56a89f4cdab1faef83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62ba34e7e0fb45ba96844393be60ddd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  2/5 | Train: 615.9460 | Val: 175.6763 | R²: qpd=-0.058, ans=-0.111, ret=-36.174 ★\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb137bc69e094180ab58ff11e9b9e28d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m best_val_loss = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUSE_AMP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device, scaler, use_amp)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Forward with AMP\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.amp.autocast(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m, enabled=use_amp, dtype=amp_dtype):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     predictions = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_graphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     loss = (\n\u001b[32m     27\u001b[39m         criterion(predictions[\u001b[33m'\u001b[39m\u001b[33mqpd\u001b[39m\u001b[33m'\u001b[39m], batch_targets[\u001b[33m'\u001b[39m\u001b[33mqpd\u001b[39m\u001b[33m'\u001b[39m]) +\n\u001b[32m     28\u001b[39m         criterion(predictions[\u001b[33m'\u001b[39m\u001b[33manswer_rate\u001b[39m\u001b[33m'\u001b[39m], batch_targets[\u001b[33m'\u001b[39m\u001b[33manswer_rate\u001b[39m\u001b[33m'\u001b[39m]) +\n\u001b[32m     29\u001b[39m         criterion(predictions[\u001b[33m'\u001b[39m\u001b[33mretention\u001b[39m\u001b[33m'\u001b[39m], batch_targets[\u001b[33m'\u001b[39m\u001b[33mretention\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     30\u001b[39m     ) / \u001b[32m3.0\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Backward with scaler\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 91\u001b[39m, in \u001b[36mTemporalCommunityGNN.forward\u001b[39m\u001b[34m(self, batch_monthly_graphs)\u001b[39m\n\u001b[32m     89\u001b[39m         x_dict = graph.x_dict\n\u001b[32m     90\u001b[39m         edge_index_dict = graph.edge_index_dict\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     emb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_single_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     monthly_embs.append(emb)\n\u001b[32m     93\u001b[39m batch_embeddings.append(torch.stack(monthly_embs))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mTemporalCommunityGNN.forward_single_graph\u001b[39m\u001b[34m(self, x_dict, edge_index_dict)\u001b[39m\n\u001b[32m     68\u001b[39m x = projected\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.convs:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     x = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     x = {k: torch.relu(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m x.items()}\n\u001b[32m     72\u001b[39m     x = {k: \u001b[38;5;28mself\u001b[39m.conv_dropout(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m x.items()}\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch_geometric/nn/conv/hetero_conv.py:159\u001b[39m, in \u001b[36mHeteroConv.forward\u001b[39m\u001b[34m(self, *args_dict, **kwargs_dict)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m out = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[32m    162\u001b[39m     out_dict[dst] = [out]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch_geometric/nn/conv/sage_conv.py:134\u001b[39m, in \u001b[36mSAGEConv.forward\u001b[39m\u001b[34m(self, x, edge_index, size)\u001b[39m\n\u001b[32m    131\u001b[39m     x = (\u001b[38;5;28mself\u001b[39m.lin(x[\u001b[32m0\u001b[39m]).relu(), x[\u001b[32m1\u001b[39m])\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m out = \u001b[38;5;28mself\u001b[39m.lin_l(out)\n\u001b[32m    137\u001b[39m x_r = x[\u001b[32m1\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_a9tjbbm_.py:229\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, x, size)\u001b[39m\n\u001b[32m    221\u001b[39m             kwargs = CollectArgs(\n\u001b[32m    222\u001b[39m                 x_j=kwargs.x_j,\n\u001b[32m    223\u001b[39m                 index=hook_kwargs[\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    224\u001b[39m                 ptr=hook_kwargs[\u001b[33m'\u001b[39m\u001b[33mptr\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    225\u001b[39m                 dim_size=hook_kwargs[\u001b[33m'\u001b[39m\u001b[33mdim_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    226\u001b[39m             )\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001b[39m, in \u001b[36mMessagePassing.aggregate\u001b[39m\u001b[34m(self, inputs, index, ptr, dim_size)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maggregate\u001b[39m(\n\u001b[32m    578\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    579\u001b[39m     inputs: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    583\u001b[39m ) -> Tensor:\n\u001b[32m    584\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[33;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[32m    586\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    592\u001b[39m \u001b[33;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[32m    593\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch_geometric/experimental.py:117\u001b[39m, in \u001b[36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[33m'\u001b[39m\u001b[33mdisable_dynamic_shapes\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[32m    120\u001b[39m         index = required_args_pos[required_arg]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch_geometric/nn/aggr/base.py:131\u001b[39m, in \u001b[36mAggregation.__call__\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     dim_size = \u001b[38;5;28mint\u001b[39m(index.max()) + \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch_geometric/nn/aggr/basic.py:36\u001b[39m, in \u001b[36mMeanAggregation.forward\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     34\u001b[39m             ptr: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     35\u001b[39m             dim: \u001b[38;5;28mint\u001b[39m = -\u001b[32m2\u001b[39m) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch_geometric/nn/aggr/base.py:185\u001b[39m, in \u001b[36mAggregation.reduce\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAggregation requires \u001b[39m\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to be specified\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch_geometric/utils/_scatter.py:75\u001b[39m, in \u001b[36mscatter\u001b[39m\u001b[34m(src, index, dim, dim_size, reduce)\u001b[39m\n\u001b[32m     73\u001b[39m count = src.new_zeros(dim_size)\n\u001b[32m     74\u001b[39m count.scatter_add_(\u001b[32m0\u001b[39m, index, src.new_ones(src.size(dim)))\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m count = \u001b[43mcount\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclamp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m index = broadcast(index, src, dim)\n\u001b[32m     78\u001b[39m out = src.new_zeros(size).scatter_add_(dim, index, src)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Starting training...\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "history = {'train_loss': [], 'val_loss': [], 'val_r2': []}\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Train\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device, scaler, USE_AMP)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_r2 = evaluate(model, val_loader, criterion, device, USE_AMP)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_r2'].append(val_r2)\n",
        "    \n",
        "    # Track best\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_marker = \" ★\"\n",
        "    else:\n",
        "        best_marker = \"\"\n",
        "    \n",
        "    print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
        "          f\"Train: {train_loss:.4f} | \"\n",
        "          f\"Val: {val_loss:.4f} | \"\n",
        "          f\"R²: qpd={val_r2['qpd']:.3f}, ans={val_r2['answer_rate']:.3f}, ret={val_r2['retention']:.3f}\"\n",
        "          f\"{best_marker}\")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "if len(history['train_loss']) > 0:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    \n",
        "    # Loss\n",
        "    ax = axes[0]\n",
        "    ax.plot(history['train_loss'], label='Train')\n",
        "    ax.plot(history['val_loss'], label='Val')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.set_title('Training Loss')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # R² scores\n",
        "    ax = axes[1]\n",
        "    for key in ['qpd', 'answer_rate', 'retention']:\n",
        "        r2_values = [h[key] for h in history['val_r2']]\n",
        "        ax.plot(r2_values, label=key)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('R²')\n",
        "    ax.set_title('Validation R² Scores')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No training history to plot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"=\"*50)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Peak GPU memory: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Mixed precision: {'bfloat16' if USE_BF16 else 'float16' if USE_AMP else 'float32'}\")\n",
        "print(f\"Total samples: {len(train_dataset)} train, {len(val_dataset)} val\")\n",
        "print(f\"\\nFinal validation loss: {history['val_loss'][-1]:.4f}\" if history['val_loss'] else \"\")\n",
        "if history['val_r2']:\n",
        "    final_r2 = history['val_r2'][-1]\n",
        "    print(f\"Final R² scores:\")\n",
        "    for k, v in final_r2.items():\n",
        "        print(f\"  {k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Next Steps\n",
        "\n",
        "Once this proof of concept runs successfully:\n",
        "\n",
        "1. **Increase data**: Set `MAX_SAMPLES = None` to use all data\n",
        "2. **Increase model size**: Try `hidden_dim=128` or `256`\n",
        "3. **More epochs**: Train for 20-50 epochs\n",
        "4. **Add test evaluation**: Create test_dataset and evaluate final model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs224w",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
